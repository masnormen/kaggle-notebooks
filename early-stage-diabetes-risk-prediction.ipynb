{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Getting Started\n\nThis is what I'm doing in this notebook:\n\n* Doing some exploratory data analysis.\n* Making predictions on the outcome of diabetes diagnosis based on the symptoms shown on patients using 7 different models + 1 voting\n* Comparing each model's prediction performance\n* Experimenting using different feature selection methods\n\nWith this notebook, I hope to learn more about data visualization and predicting outcomes using Python. Any upvote, comment, and suggestion will be very appreciated!"},{"metadata":{},"cell_type":"markdown","source":"# Importing Library and Dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\nimport seaborn as sns\nsns.set_palette(\"bwr\")\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import cross_val_score\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Taking a look on our dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Data\n\n### Checking null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.isnull(), cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Standardize column names and map boolean values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make column name lowercase and convert space to underscore\ndf.columns = map(str.lower, df.columns)\ndf.columns = df.columns.str.strip()\ndf.columns = df.columns.str.replace(\" \", \"_\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Map yes/no values\none_values = [\"Male\", \"Positive\", \"Yes\"]\nzero_values = [\"Female\", \"Negative\", \"No\"]\n\nfor column in df.columns:\n    df[column] = df[column].replace(to_replace=[one_values], value=1)\n    df[column] = df[column].replace(to_replace=[zero_values], value=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will also rename \"class\" column into \"status\""},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.rename({\"class\": \"status\"}, axis = \"columns\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring Our Data\n\n### Status and gender distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a function to plot a simple pie chart\ndef plotPie(value, title, label):\n    plt.figure(figsize=(4,4))\n    plt.pie(\n        value.value_counts(),\n        startangle=90,\n        labels = label,\n        autopct=(lambda p:f'{p:.2f}%\\n{p*sum(value.value_counts())/100 :.0f} items')\n    )\n    plt.title(title)\n    plt.show()\n\nplotPie(df[\"status\"], \"Status distribution\", [\"Positive\", \"Negative\"])\nplotPie(df[\"gender\"], \"Gender distribution\", [\"Male\", \"Female\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Age distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(5,5))\n\nax = sns.distplot(df[\"age\"], color=\"r\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Status in relation with gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x=\"status\", data=df, hue=\"gender\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Status in relation with age"},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.violinplot(x=\"status\", y=\"age\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Divide data into positive and negative class data\ndf_pos = df[df[\"status\"] == 1]\ndf_neg = df[df[\"status\"] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average positive age:\", df_pos[\"age\"].mean())\nprint(\"Average negative age:\", df_neg[\"age\"].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation visualization between symptoms and diabetes status"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_symptoms = df[df.columns.difference([\"age\", \"status\", \"gender\"])]\n\nfor column in df_symptoms.columns:\n    plt.figure(figsize=(4,4))\n    ax = sns.barplot(x=column, y=\"status\", data=df)\n    ax.set_xticklabels([\"No\", \"Yes\"])\n    ax.set_ylabel(\"Diabetes risk\")\n    ax.set_xlabel(None)\n    title = column.capitalize()\n    plt.title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Occurences of symptoms in all patients"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select only the symptom columns\ndf_symptoms = df[df.columns.difference([\"age\", \"status\", \"gender\"])]\nplt.figure(figsize=(5,5))\nfor column in df_symptoms.columns:\n    plotPie(df_symptoms[column], column.capitalize(), [\"Yes\", \"No\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\n\ncorr = df.corr()\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 160, n=256),\n    square=True,\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=50,\n    horizontalalignment=\"right\"\n);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can briefly see that polyuria and polydipsia have the strongest positive correlations with status, and gender has the strongest negative correlation."},{"metadata":{},"cell_type":"markdown","source":"# Building Models\n\n## (1) Features selection: with Pearson's\n\nWe will select top 10 features with the highest absolute value of Pearson's correlation coefficient."},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_corr = df.corr()[\"status\"].to_frame()\nfeat_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort values with highest correlation\nfeat_corr[\"status\"] = abs(feat_corr[\"status\"])\nfeat_corr = feat_corr.sort_values(by=\"status\", ascending=False).reset_index(drop=False)\nfeat_corr = feat_corr[1:11][\"index\"].to_numpy()\nfeat_corr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (1.a) Dividing dataset into training and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = df[feat_corr]\ny = df[\"status\"]\n\n(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size = 0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (1.b) Scaling and standardizing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscl = StandardScaler()\nx_train = scl.fit_transform(x_train)\nx_test = scl.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (1.c) Baseline validation\n\nWe'd like to see how different models perform with default parameters. We'll be using ten fold cross validation to get a baseline."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining objects for the models and creating a list to iterate the process\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nnb = GaussianNB()\nlr = LogisticRegression(max_iter = 2000)\ndt = tree.DecisionTreeClassifier(random_state = 1)\nrf = RandomForestClassifier(random_state = 1)\nsvc = SVC(probability = True)\nknn = KNeighborsClassifier()\nxgb = XGBClassifier(random_state =1)\nvot = VotingClassifier(\n    estimators = [('nb',nb), ('lr',lr), ('dt',dt), ('rf',rf), ('svc',svc), ('knn',knn), ('xgb',xgb)],\n    voting = 'soft'\n)\n\nmodels = [nb, lr, dt, rf, svc, knn, xgb, vot]\nmodels_name = [\n    \"Naive Bayes\",\n    \"Logistic Regression\",\n    \"Decision Tree\",\n    \"Random Forest\",\n    \"SVM\",\n    \"K-Nearest Neighbor\",\n    \"XGBoost\",\n    \"Voting\"\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_base = {}\n\nfor index, model in enumerate(models):\n    cv = cross_val_score(model, x_train, y_train, cv=10)\n    results_base[models_name[index]] = cv.mean() * 100.0\n    print(\"Baseline using\", models_name[index], \"=\", cv.mean() * 100.0, \"%\", \"with std:\", cv.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (1.d) Predicting data\n\nWe'll also take a look at the confusion matrix of each model."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix\n\nresults = {}\n\nfor index, model in enumerate(models):\n    model.fit(x_train, y_train)\n    predict = model.predict(x_test)\n    confuse = confusion_matrix(y_test, predict)\n    accur = accuracy_score(y_test, predict)\n    results[models_name[index]] = accur * 100.0\n    \n    title = models_name[index] + \": \" + \"{:.3f}%\".format(accur*100) + \" accurate\\n\"\n    ax = sns.heatmap(confuse/np.sum(confuse), annot=True, fmt='.1%', cmap=\"Greens\")\n    ax.set_title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (1.e) Comparing performance with baseline"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(len(results))\n\nplt.figure(figsize=(9,5))\nax = plt.subplot(111)\nax.bar(x, results_base.values(), width=0.4, color=\"c\", align=\"center\")\nax.bar(x+0.4, results.values(), width=0.4, color=\"r\", align=\"center\")\nax.legend((\"Base\", \"Real\"))\nplt.ylim((85, 100))\nplt.xticks(x+0.4, results_base.keys())\nplt.title(\"Performance comparison\")\nplt.xticks(rotation=40, horizontalalignment=\"right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## (2) Features selection: with Chi-Squared test\n\nWe will select top 10 features with the highest Chi-squared value."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import SelectKBest\n\nx = df[df.columns.difference([\"status\"])]\ny = df[\"status\"]\n\nfeat_chi = SelectKBest(score_func=chi2, k=10)\nfit = feat_chi.fit(x, y)\nfeat_chi = pd.concat([pd.DataFrame(x.columns), pd.DataFrame(fit.scores_)], axis=1)\nfeat_chi.columns = [\"column\", \"score\"]\nfeat_chi = feat_chi.sort_values(by=\"score\", ascending=False).reset_index(drop=False)\nfeat_chi = feat_chi[0:10][\"column\"].to_numpy()\nprint(feat_chi)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compare it to the list of feature selection we've created earlier using Pearson's correlation coefficient. There is some difference between both of them. Let's check."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(feat_corr)\nprint()\nprint(\"Difference:\", list(set(feat_corr).symmetric_difference(set(feat_chi))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (2.a) Dividing dataset into training and test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df[feat_chi]\ny = df[\"status\"]\n\n(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size = 0.2, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (2.b) Standardizing and scaling the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"scl = StandardScaler()\nx_train = scl.fit_transform(x_train)\nx_test = scl.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (2.c) Baseline validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"results_base = {}\n\nfor index, model in enumerate(models):\n    cv = cross_val_score(model, x_train, y_train, cv=10)\n    results_base[models_name[index]] = cv.mean() * 100.0\n    print(\"Baseline using\", models_name[index], \"=\", cv.mean() * 100.0, \"%\", \"with std:\", cv.std())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (2.d) Predicting data"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = {}\n\nfor index, model in enumerate(models):\n    model.fit(x_train, y_train)\n    predict = model.predict(x_test)\n    confuse = confusion_matrix(y_test, predict)\n    accur = accuracy_score(y_test, predict)\n    results[models_name[index]] = accur * 100.0\n    \n    title = models_name[index] + \": \" + \"{:.3f}%\".format(accur*100) + \" accurate\\n\"\n    ax = sns.heatmap(confuse/np.sum(confuse), annot=True, fmt='.1%', cmap=\"Greens\")\n    ax.set_title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### (2.e) Comparing performance with baseline"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(len(results))\n\nplt.figure(figsize=(9,5))\nax = plt.subplot(111)\nax.bar(x, results_base.values(), width=0.4, color=\"c\", align=\"center\")\nax.bar(x+0.4, results.values(), width=0.4, color=\"r\", align=\"center\")\nax.legend((\"Base\", \"Real\"))\nplt.ylim((85, 100))\nplt.xticks(x+0.4, results_base.keys())\nplt.title(\"Performance comparison\")\nplt.xticks(rotation=40, horizontalalignment=\"right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\nSo, in this notebook, I experimented with different features selection methods and models. It turns out that using chi-squared method is best for categorical input and categorical output. After comparing the models above, the best models for predicting diabetes in this dataset are XGBoost, Random Forest, and Decision Tree using both features selection methods.\n\nThe best accuracy I can get is with XGBoost and Random Forest, both with 97.1% accuracy with feature selection done using chi-squared.\n\nAny upvote, comment, and suggestion will be very appreciated! Thank you."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}