{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "This is what I'm doing in this notebook:\n",
    "\n",
    "* Doing some exploratory data analysis.\n",
    "* Making predictions on the outcome of diabetes diagnosis based on the symptoms shown on patients using 7 different models + 1 voting\n",
    "* Comparing each model's prediction performance\n",
    "* Experimenting using different feature selection methods\n",
    "\n",
    "With this notebook, I hope to learn more about data visualization and predicting outcomes using Python. Any upvote, comment, and suggestion will be very appreciated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"bwr\")\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a look on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /kaggle/input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv does not exist: '/kaggle/input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-345c9fb8b26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /kaggle/input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv does not exist: '/kaggle/input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/early-stage-diabetes-risk-prediction-dataset/diabetes_data_upload.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "\n",
    "### Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize column names and map boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column name lowercase and convert space to underscore\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns = df.columns.str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map yes/no values\n",
    "one_values = [\"Male\", \"Positive\", \"Yes\"]\n",
    "zero_values = [\"Female\", \"Negative\", \"No\"]\n",
    "\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].replace(to_replace=[one_values], value=1)\n",
    "    df[column] = df[column].replace(to_replace=[zero_values], value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also rename \"class\" column into \"status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\"class\": \"status\"}, axis = \"columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Our Data\n",
    "\n",
    "### Status and gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to plot a simple pie chart\n",
    "def plotPie(value, title, label):\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.pie(\n",
    "        value.value_counts(),\n",
    "        startangle=90,\n",
    "        labels = label,\n",
    "        autopct=(lambda p:f'{p:.2f}%\\n{p*sum(value.value_counts())/100 :.0f} items')\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plotPie(df[\"status\"], \"Status distribution\", [\"Positive\", \"Negative\"])\n",
    "plotPie(df[\"gender\"], \"Gender distribution\", [\"Male\", \"Female\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "ax = sns.distplot(df[\"age\"], color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status in relation with gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"status\", data=df, hue=\"gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status in relation with age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"status\", y=\"age\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into positive and negative class data\n",
    "df_pos = df[df[\"status\"] == 1]\n",
    "df_neg = df[df[\"status\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average positive age:\", df_pos[\"age\"].mean())\n",
    "print(\"Average negative age:\", df_neg[\"age\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation visualization between symptoms and diabetes status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_symptoms = df[df.columns.difference([\"age\", \"status\", \"gender\"])]\n",
    "\n",
    "for column in df_symptoms.columns:\n",
    "    plt.figure(figsize=(4,4))\n",
    "    ax = sns.barplot(x=column, y=\"status\", data=df)\n",
    "    ax.set_xticklabels([\"No\", \"Yes\"])\n",
    "    ax.set_ylabel(\"Diabetes risk\")\n",
    "    ax.set_xlabel(None)\n",
    "    title = column.capitalize()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occurences of symptoms in all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the symptom columns\n",
    "df_symptoms = df[df.columns.difference([\"age\", \"status\", \"gender\"])]\n",
    "plt.figure(figsize=(5,5))\n",
    "for column in df_symptoms.columns:\n",
    "    plotPie(df_symptoms[column], column.capitalize(), [\"Yes\", \"No\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "corr = df.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 160, n=256),\n",
    "    square=True,\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=50,\n",
    "    horizontalalignment=\"right\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can briefly see that polyuria and polydipsia have the strongest positive correlations with status, and gender has the strongest negative correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models\n",
    "\n",
    "## (1) Features selection: with Pearson's\n",
    "\n",
    "We will select top 10 features with the highest absolute value of Pearson's correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_corr = df.corr()[\"status\"].to_frame()\n",
    "feat_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values with highest correlation\n",
    "feat_corr[\"status\"] = abs(feat_corr[\"status\"])\n",
    "feat_corr = feat_corr.sort_values(by=\"status\", ascending=False).reset_index(drop=False)\n",
    "feat_corr = feat_corr[1:11][\"index\"].to_numpy()\n",
    "feat_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.a) Dividing dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df[feat_corr]\n",
    "y = df[\"status\"]\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.b) Scaling and standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scl = StandardScaler()\n",
    "x_train = scl.fit_transform(x_train)\n",
    "x_test = scl.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.c) Baseline validation\n",
    "\n",
    "We'd like to see how different models perform with default parameters. We'll be using ten fold cross validation to get a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining objects for the models and creating a list to iterate the process\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "nb = GaussianNB()\n",
    "lr = LogisticRegression(max_iter = 2000)\n",
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "rf = RandomForestClassifier(random_state = 1)\n",
    "svc = SVC(probability = True)\n",
    "knn = KNeighborsClassifier()\n",
    "xgb = XGBClassifier(random_state =1)\n",
    "vot = VotingClassifier(\n",
    "    estimators = [('nb',nb), ('lr',lr), ('dt',dt), ('rf',rf), ('svc',svc), ('knn',knn), ('xgb',xgb)],\n",
    "    voting = 'soft'\n",
    ")\n",
    "\n",
    "models = [nb, lr, dt, rf, svc, knn, xgb, vot]\n",
    "models_name = [\n",
    "    \"Naive Bayes\",\n",
    "    \"Logistic Regression\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"SVM\",\n",
    "    \"K-Nearest Neighbor\",\n",
    "    \"XGBoost\",\n",
    "    \"Voting\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = {}\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    cv = cross_val_score(model, x_train, y_train, cv=10)\n",
    "    results_base[models_name[index]] = cv.mean() * 100.0\n",
    "    print(\"Baseline using\", models_name[index], \"=\", cv.mean() * 100.0, \"%\", \"with std:\", cv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.d) Predicting data\n",
    "\n",
    "We'll also take a look at the confusion matrix of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "results = {}\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    model.fit(x_train, y_train)\n",
    "    predict = model.predict(x_test)\n",
    "    confuse = confusion_matrix(y_test, predict)\n",
    "    accur = accuracy_score(y_test, predict)\n",
    "    results[models_name[index]] = accur * 100.0\n",
    "    \n",
    "    title = models_name[index] + \": \" + \"{:.3f}%\".format(accur*100) + \" accurate\\n\"\n",
    "    ax = sns.heatmap(confuse/np.sum(confuse), annot=True, fmt='.1%', cmap=\"Greens\")\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.e) Comparing performance with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(results))\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(x, results_base.values(), width=0.4, color=\"c\", align=\"center\")\n",
    "ax.bar(x+0.4, results.values(), width=0.4, color=\"r\", align=\"center\")\n",
    "ax.legend((\"Base\", \"Real\"))\n",
    "plt.ylim((85, 100))\n",
    "plt.xticks(x+0.4, results_base.keys())\n",
    "plt.title(\"Performance comparison\")\n",
    "plt.xticks(rotation=40, horizontalalignment=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Features selection: with Chi-Squared test\n",
    "\n",
    "We will select top 10 features with the highest Chi-squared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "x = df[df.columns.difference([\"status\"])]\n",
    "y = df[\"status\"]\n",
    "\n",
    "feat_chi = SelectKBest(score_func=chi2, k=10)\n",
    "fit = feat_chi.fit(x, y)\n",
    "feat_chi = pd.concat([pd.DataFrame(x.columns), pd.DataFrame(fit.scores_)], axis=1)\n",
    "feat_chi.columns = [\"column\", \"score\"]\n",
    "feat_chi = feat_chi.sort_values(by=\"score\", ascending=False).reset_index(drop=False)\n",
    "feat_chi = feat_chi[0:10][\"column\"].to_numpy()\n",
    "print(feat_chi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it to the list of feature selection we've created earlier using Pearson's correlation coefficient. There is some difference between both of them. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_corr)\n",
    "print()\n",
    "print(\"Difference:\", list(set(feat_corr).symmetric_difference(set(feat_chi))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.a) Dividing dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[feat_chi]\n",
    "y = df[\"status\"]\n",
    "\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(x, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.b) Standardizing and scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "x_train = scl.fit_transform(x_train)\n",
    "x_test = scl.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.c) Baseline validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = {}\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    cv = cross_val_score(model, x_train, y_train, cv=10)\n",
    "    results_base[models_name[index]] = cv.mean() * 100.0\n",
    "    print(\"Baseline using\", models_name[index], \"=\", cv.mean() * 100.0, \"%\", \"with std:\", cv.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.d) Predicting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    model.fit(x_train, y_train)\n",
    "    predict = model.predict(x_test)\n",
    "    confuse = confusion_matrix(y_test, predict)\n",
    "    accur = accuracy_score(y_test, predict)\n",
    "    results[models_name[index]] = accur * 100.0\n",
    "    \n",
    "    title = models_name[index] + \": \" + \"{:.3f}%\".format(accur*100) + \" accurate\\n\"\n",
    "    ax = sns.heatmap(confuse/np.sum(confuse), annot=True, fmt='.1%', cmap=\"Greens\")\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.e) Comparing performance with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(results))\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(x, results_base.values(), width=0.4, color=\"c\", align=\"center\")\n",
    "ax.bar(x+0.4, results.values(), width=0.4, color=\"r\", align=\"center\")\n",
    "ax.legend((\"Base\", \"Real\"))\n",
    "plt.ylim((85, 100))\n",
    "plt.xticks(x+0.4, results_base.keys())\n",
    "plt.title(\"Performance comparison\")\n",
    "plt.xticks(rotation=40, horizontalalignment=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "So, in this notebook, I experimented with different features selection methods and models. It turns out that using chi-squared method is best for categorical input and categorical output. After comparing the models above, the best models for predicting diabetes in this dataset are XGBoost, Random Forest, and Decision Tree using both features selection methods.\n",
    "\n",
    "The best accuracy I can get is with XGBoost and Random Forest, both with 97.1% accuracy with feature selection done using chi-squared.\n",
    "\n",
    "Any upvote, comment, and suggestion will be very appreciated! Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
